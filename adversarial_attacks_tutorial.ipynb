{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "adversarial-attacks-tutorial.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNU+p033ADRHHnJcxp2fLb6"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkgd_-0BDRpU"
      },
      "source": [
        "# Adversarial Attacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sl7AjTxlDcAg"
      },
      "source": [
        "## Install and import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxhLpaMAl5QJ"
      },
      "source": [
        "# If you want to run this outside of Colab you will need to install the\n",
        "# appropriate libraries, e.g, Pytorch, etc.\n",
        "! pip install adversarial-robustness-toolbox\n",
        "! pip install IPython\n",
        "! pillow\n",
        "! pip install yaspin\n",
        "\n",
        "! rm -rf repo \n",
        "! git clone https://github.com/jalane76/adversarial-attacks-tutorial.git repo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtTFhkbNaZiF"
      },
      "source": [
        "from art.attacks.evasion import FastGradientMethod\n",
        "from art.estimators.classification import PyTorchClassifier\n",
        "from art.utils import load_mnist\n",
        "import IPython\n",
        "from IPython.display import display\n",
        "from IPython.display import Image as DisplayImage\n",
        "import matplotlib\n",
        "from matplotlib.colors import TwoSlopeNorm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image as PILImage\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from yaspin import yaspin\n",
        "from yaspin.spinners import Spinners"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxK21jIeDkjD"
      },
      "source": [
        "## Set up app parameters and helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mawb8Gm0bMpK"
      },
      "source": [
        "rand_seed = 978614566\n",
        "np.random.seed(rand_seed)\n",
        "torch.manual_seed(rand_seed)\n",
        "\n",
        "image_width = 28\n",
        "image_height = 28\n",
        "input_shape = (1, 28, 28)\n",
        "\n",
        "batch_size = 64\n",
        "num_epochs = 3\n",
        "num_labels = 10\n",
        "\n",
        "def increase_font():\n",
        "  from IPython.display import Javascript\n",
        "  display(Javascript('''\n",
        "    for (rule of document.styleSheets[0].cssRules){\n",
        "      if (rule.selectorText=='body') {\n",
        "        rule.style.fontSize = '30px'\n",
        "        break\n",
        "      }\n",
        "    }\n",
        "  '''))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OH095STvDuxT"
      },
      "source": [
        "## We'll use the MNIST dataset so load it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYKWIf5lbiqi"
      },
      "source": [
        "with yaspin(spinner=Spinners.aesthetic, text=\"Loading MNIST data...\"):\n",
        "  (\n",
        "    (x_train, y_train),\n",
        "    (x_test, y_test),\n",
        "    min_pixel_value,\n",
        "    max_pixel_value,\n",
        "  ) = load_mnist()\n",
        "\n",
        "  clip_values = (min_pixel_value, max_pixel_value)\n",
        "\n",
        "  # Swap axes to PyTorch's NCHW format\n",
        "  x_train = np.transpose(x_train, (0, 3, 1, 2)).astype(np.float32)\n",
        "  x_test = np.transpose(x_test, (0, 3, 1, 2)).astype(np.float32)\n",
        "\n",
        "  # Invert grayscale for black characters on a white background\n",
        "  x_train = max_pixel_value - x_train\n",
        "  x_test = max_pixel_value - x_test\n",
        "\n",
        "print(f\"  Training data shape: {x_train.shape}\")\n",
        "print(f\"Training labels shape: {y_train.shape}\")\n",
        "print(f\"      Test data shape: {x_test.shape}\")\n",
        "print(f\"    Test labels shape: {y_test.shape}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqzcOr8mD6dH"
      },
      "source": [
        "## Let's see the first few benign samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbd2S9gDh9cg",
        "collapsed": true
      },
      "source": [
        "with yaspin(spinner=Spinners.aesthetic, text=\"Plotting benign samples...\"):\n",
        "  num_samples = 5\n",
        "  num_rows = 1\n",
        "\n",
        "  fig, axes = plt.subplots(num_rows, num_samples, sharex=True, sharey=True, squeeze=False)\n",
        "  fig.set_figheight(4.0 * num_rows)\n",
        "  fig.set_figwidth(4.0 * num_samples)\n",
        "  for sample_idx in range(num_samples):\n",
        "    sample_axis = axes[0, sample_idx]\n",
        "    sample = x_train[sample_idx, 0, :, :]\n",
        "    sample_axis.imshow(\n",
        "      sample, cmap=\"gray\", aspect=\"equal\", interpolation=\"nearest\"\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7eKzeq1Ec5z"
      },
      "source": [
        "## Define the neural network and create an ART classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wO79crGufkoE"
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.conv_1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=5, stride=1)\n",
        "    self.conv_2 = nn.Conv2d(in_channels=4, out_channels=10, kernel_size=5, stride=1)\n",
        "    self.fc_1 = nn.Linear(in_features=4 * 4 * 10, out_features=100)\n",
        "    self.fc_2 = nn.Linear(in_features=100, out_features=10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv_1(x))\n",
        "    x = F.max_pool2d(x, 2, 2)\n",
        "    x = F.relu(self.conv_2(x))\n",
        "    x = F.max_pool2d(x, 2, 2)\n",
        "    x = x.view(-1, 4 * 4 * 10)\n",
        "    x = F.relu(self.fc_1(x))\n",
        "    x = self.fc_2(x)\n",
        "    return x\n",
        "\n",
        "model = Net()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "classifier = PyTorchClassifier(\n",
        "  model=model,\n",
        "  clip_values=clip_values,\n",
        "  loss=criterion,\n",
        "  optimizer=optimizer,\n",
        "  input_shape=(input_shape),\n",
        "  nb_classes=num_labels,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nN96nKYgEkTs"
      },
      "source": [
        "## Train the classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0yZo7Tk_mVe"
      },
      "source": [
        "with yaspin(spinner=Spinners.aesthetic, text=\"Training...\"):\n",
        "  classifier.fit(x_train, y_train, batch_size=batch_size, nb_epochs=num_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyW4oRo-EruU"
      },
      "source": [
        "## Test the accuracy on benign samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ko38ysEUD2rr"
      },
      "source": [
        "predictions = classifier.predict(x_test)\n",
        "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
        "increase_font()\n",
        "print(f\"Benign accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "display(DisplayImage(open('repo/airplane-thumbs-up.gif','rb').read()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzqeKz3qE4XY"
      },
      "source": [
        "#    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjoovhB9FI-W"
      },
      "source": [
        "## Now generate FGSM attacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvEKpttzHhd6"
      },
      "source": [
        "with yaspin(spinner=Spinners.aesthetic, text=\"Generating attacks...\"):\n",
        "  attack = FastGradientMethod(estimator=classifier, eps=0.2)\n",
        "  x_test_adv = attack.generate(x=x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooC24lr5FZMd"
      },
      "source": [
        "## Now let's compare the first few benign samples with their evil twins"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibQv0_T1KdUT"
      },
      "source": [
        "with yaspin(spinner=Spinners.aesthetic, text=\"Generating training attacks and retraining...\"):\n",
        "  num_samples = 5\n",
        "  num_rows = 2\n",
        "\n",
        "  fig, axes = plt.subplots(num_rows, num_samples, sharex=True, sharey=True, squeeze=False)\n",
        "  fig.set_figheight(4.0 * num_rows)\n",
        "  fig.set_figwidth(4.0 * num_samples)\n",
        "  for sample_idx in range(num_samples):\n",
        "    sample_axis = axes[0, sample_idx]\n",
        "    sample = x_test[sample_idx, 0, :, :]\n",
        "    sample_axis.imshow(\n",
        "      sample, cmap=\"gray\", aspect=\"equal\", interpolation=\"nearest\"\n",
        "    )\n",
        "\n",
        "    evil_twin_axis = axes[1, sample_idx]\n",
        "    evil_twin = x_test_adv[sample_idx, 0, :, :]\n",
        "    evil_twin_axis.imshow(\n",
        "        evil_twin, cmap=\"gray\", aspect=\"equal\", interpolation=\"nearest\"\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4bsLJ7uFhzq"
      },
      "source": [
        "## Test the accuracy on the adversarial examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFtuuG-QHt2t"
      },
      "source": [
        "predictions = classifier.predict(x_test_adv)\n",
        "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
        "increase_font()\n",
        "print(f\"Adversarial accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "display(DisplayImage(open('repo/airplane-sweat.gif','rb').read()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pd5rJxybF3jq"
      },
      "source": [
        "## Let's augment the training data with adversarial examples and retrain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76rR93hzOh9t"
      },
      "source": [
        "with yaspin(spinner=Spinners.aesthetic, text=\"Generating training attacks and retraining...\"):\n",
        "  x_train_adv = attack.generate(x=x_train)\n",
        "  classifier.fit(x_train_adv, y_train, batch_size=batch_size, nb_epochs=num_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3KuJ4AOF_b3"
      },
      "source": [
        "## Retest the accuracy after retraining"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAPLATqAPwMa"
      },
      "source": [
        "predictions = classifier.predict(x_test_adv)\n",
        "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
        "increase_font()\n",
        "print(f\"Retrained accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "display(DisplayImage(open('repo/airplane-happy.gif','rb').read()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReJ6YC-NcKSS"
      },
      "source": [
        "# Runway Numbers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaN_OtudcQDn"
      },
      "source": [
        "## Let's now generate a set of runway numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSqJdAmteXQn"
      },
      "source": [
        "# First digit\n",
        "# Filter out all digits greater than 4 since they are not valid runway number digits\n",
        "first_digit_indices = (np.argmax(y_test, axis=1) <= 3)\n",
        "first_benign_digits = x_test[first_digit_indices]\n",
        "first_evil_digits = x_test_adv[first_digit_indices]\n",
        "first_labels = y_test[first_digit_indices]\n",
        "\n",
        "# Let's just round our number of samples down to the nearest thousands\n",
        "new_size = int(np.fix(first_benign_digits.shape[0] // 1000) * 1000)\n",
        "first_benign_digits = first_benign_digits[:new_size]\n",
        "first_evil_digits = first_evil_digits[:new_size]\n",
        "first_labels = first_labels[:new_size]\n",
        "\n",
        "# Make a random boolean array and use it to select between benign and evil digits\n",
        "select_indices = np.full((new_size, 1, 1, 1), False)\n",
        "select_indices[:int(new_size/2)] = True\n",
        "np.random.shuffle(select_indices)\n",
        "first_digits = np.where(select_indices, first_benign_digits, first_evil_digits)\n",
        "\n",
        "# Second digit\n",
        "# Select again between benign and evil digits\n",
        "select_indices = np.full(x_test.shape[0], False)\n",
        "select_indices[:int(x_test.shape[0]/2)] = True\n",
        "np.random.shuffle(select_indices)\n",
        "second_digits = np.where(select_indices.reshape((x_test.shape[0], 1, 1, 1)), x_test, x_test_adv)\n",
        "second_labels = y_test\n",
        "\n",
        "# Trim second digits set down to the same size as the first digit set\n",
        "second_digits = second_digits[:new_size]\n",
        "second_labels = second_labels[:new_size]\n",
        "\n",
        "# Let's shuffle each set of digits so we don't get overlap\n",
        "shuffle_indices = np.arange(new_size)\n",
        "np.random.shuffle(shuffle_indices)\n",
        "first_digits = first_digits[shuffle_indices]\n",
        "first_labels = first_labels[shuffle_indices]\n",
        "\n",
        "# Shuffle again for second digit\n",
        "np.random.shuffle(shuffle_indices)\n",
        "second_digits = second_digits[shuffle_indices]\n",
        "second_labels = second_labels[shuffle_indices]\n",
        "\n",
        "# Stitch the first and second digits into the same tensor\n",
        "digits = np.concatenate((first_digits, second_digits), axis=1)\n",
        "labels = np.stack((first_labels, second_labels), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f90BiVuYFHf"
      },
      "source": [
        "## Next we'll import some images of perfect runway number digits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRK4rkfHYX62"
      },
      "source": [
        "digit_icons = np.full((num_labels, image_width, image_height), 0.0)\n",
        "for i in range(num_labels):\n",
        "  image = np.asarray(PILImage.open(f'repo/{i}.png').convert('L'))\n",
        "  digit_icons[i::] = image\n",
        "\n",
        "with yaspin(spinner=Spinners.aesthetic, text=\"Plotting benign samples...\"):\n",
        "  num_samples = 10\n",
        "  num_rows = 1\n",
        "\n",
        "  fig, axes = plt.subplots(num_rows, num_samples, sharex=True, sharey=True, squeeze=False)\n",
        "  fig.set_figheight(4.0 * num_rows)\n",
        "  fig.set_figwidth(4.0 * num_samples)\n",
        "  for sample_idx in range(num_samples):\n",
        "    sample_axis = axes[0, sample_idx]\n",
        "    sample = digit_icons[sample_idx, :, :]\n",
        "    sample_axis.imshow(\n",
        "      sample, cmap=\"gray\", aspect=\"equal\", interpolation=\"nearest\"\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Q-xFKePCZVj"
      },
      "source": [
        "## Run the classifier on the \"runway numbers\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbpqgYRODDzd"
      },
      "source": [
        "with yaspin(spinner=Spinners.aesthetic, text=\"Classifying runway numbers...\"):\n",
        "  predictions = classifier.predict(digits.reshape(new_size*2, 1, image_width, image_height)).reshape(new_size, 2, num_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vn0-539HFcR-"
      },
      "source": [
        "## Run a \"monitor\" on the predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6PcVL2JFj3o"
      },
      "source": [
        "first_digit_monitor = (np.argmax(predictions[:,0,:], axis=1) >= 0) & (np.argmax(predictions[:,0,:], axis=1) <= 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9NLNotGLtgH"
      },
      "source": [
        "## Let's see how we did"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4-DTcBSQLlu"
      },
      "source": [
        "first_digit_successes = np.sum(np.argmax(predictions[:,0,:], axis=1) == np.argmax(labels[:,0,:], axis=1))\n",
        "first_digit_errors = predictions.shape[0] - first_digit_successes\n",
        "first_digit_accuracy = first_digit_successes / predictions.shape[0]\n",
        "second_digit_accuracy = np.sum(np.argmax(predictions[:,1,:], axis=1) == np.argmax(labels[:,1,:], axis=1)) / predictions.shape[0]\n",
        "monitor_catches = np.sum(first_digit_monitor == False)\n",
        "\n",
        "increase_font()\n",
        "print(f\"First digit errors: {first_digit_errors}\")\n",
        "print(f\"First digit accuracy: {first_digit_accuracy * 100:.2f}%\")\n",
        "print(f\"Second digit accuracy: {second_digit_accuracy * 100:.2f}%\")\n",
        "print(f\"Monitor catches: {monitor_catches}\")\n",
        "print(f\"Monitor savings: {monitor_catches / first_digit_errors * 100:.2f}%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01J9K4uRdZ-f"
      },
      "source": [
        "## Let's find examples of\n",
        "*   A correctly predicted runway number\n",
        "*   An incorrectly predicted runway number where the 2nd number is incorrect\n",
        "*   An incorrectly predicted runway number where the 1st number is incorrect, but the monitor **was not** triggered\n",
        "*   An incorrectly predicted runway number where the 1st number is incorrect, but the monitor **was** triggered\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "076Ulm8FeO3C"
      },
      "source": [
        "correct_first_digits = np.argmax(predictions[:,0,:], axis=1) == np.argmax(labels[:,0,:], axis=1)\n",
        "correct_second_digits = np.argmax(predictions[:,1,:], axis=1) == np.argmax(labels[:,1,:], axis=1)\n",
        "\n",
        "correct_idx = np.argwhere((correct_first_digits & correct_second_digits))[0][0]\n",
        "incorrect_2_idx = np.argwhere(correct_first_digits & np.logical_not(correct_second_digits))[0][0]\n",
        "incorrect_1_idx = np.argwhere(np.logical_not(correct_first_digits) & correct_second_digit & first_digit_monitor)[0][0]\n",
        "incorrect_monitor_idx = np.argwhere(np.logical_not(first_digit_monitor))[0][0]\n",
        "\n",
        "example_indices = [(0, correct_idx), (1, incorrect_2_idx), (2, incorrect_1_idx), (3, incorrect_monitor_idx)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzViaZDeYR7Z"
      },
      "source": [
        "# Finally, let's plot some examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bib6NpqBLwgt"
      },
      "source": [
        "with yaspin(spinner=Spinners.aesthetic, text=\"Plotting runway numbers outcomes...\"):\n",
        "  num_rows = 4\n",
        "  num_columns = 6\n",
        "\n",
        "  col_titles = [\n",
        "    'Input 1',\n",
        "    'Input 2',\n",
        "    'Prediction 1',\n",
        "    'Prediction 2',\n",
        "    'Ground Truth 1',\n",
        "    'Ground Truth 2'\n",
        "  ]\n",
        "\n",
        "  input_color = \"Greys_r\"\n",
        "  success_color = \"Greens_r\"\n",
        "  failure_color = \"Reds_r\"\n",
        "  truth_color = \"Blues_r\"\n",
        "\n",
        "  fig, axes = plt.subplots(num_rows, num_columns, sharex=True, sharey=True, squeeze=False)\n",
        "  fig.set_figheight(4.0 * num_rows)\n",
        "  fig.set_figwidth(4.0 * num_rows)\n",
        "\n",
        "  for col_idx in range(num_columns):\n",
        "    axes[0, col_idx].set_title(col_titles[col_idx])\n",
        "\n",
        "  for row_idx, example_idx in example_indices:\n",
        "    input1 = digits[example_idx, 0, :, :]\n",
        "    input2 = digits[example_idx, 1, :, :]\n",
        "    prediction1 = digit_icons[np.argmax(predictions[example_idx, 0, :])]\n",
        "    prediction2 = digit_icons[np.argmax(predictions[example_idx, 1, :])]\n",
        "    truth1 = digit_icons[np.argmax(labels[example_idx, 0, :])]\n",
        "    truth2 = digit_icons[np.argmax(labels[example_idx, 1, :])]\n",
        "\n",
        "    axes[row_idx, 0].imshow(\n",
        "      input1, cmap=input_color, aspect=\"equal\", interpolation=\"nearest\"\n",
        "    )\n",
        "    axes[row_idx, 1].imshow(\n",
        "      input2, cmap=input_color, aspect=\"equal\", interpolation=\"nearest\"\n",
        "    )\n",
        "\n",
        "    pred_color = success_color if first_digit_monitor[example_idx] and np.array_equal(prediction1, truth1) else failure_color\n",
        "    axes[row_idx, 2].imshow(\n",
        "      prediction1, cmap=pred_color, aspect=\"equal\", interpolation=\"nearest\"\n",
        "    )\n",
        "    pred_color = success_color if np.array_equal(prediction2, truth2) else failure_color\n",
        "    axes[row_idx, 3].imshow(\n",
        "      prediction2, cmap=pred_color, aspect=\"equal\", interpolation=\"nearest\"\n",
        "    )\n",
        "\n",
        "    axes[row_idx, 4].imshow(\n",
        "      truth1, cmap=truth_color, aspect=\"equal\", interpolation=\"nearest\"\n",
        "    )\n",
        "    axes[row_idx, 5].imshow(\n",
        "      truth2, cmap=truth_color, aspect=\"equal\", interpolation=\"nearest\"\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}