{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "adversarial-attacks-tutorial.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPk8UIKqqCmToZmZ4ibDYUz"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkgd_-0BDRpU"
      },
      "source": [
        "# Adversarial Attacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sl7AjTxlDcAg"
      },
      "source": [
        "## Install and import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxhLpaMAl5QJ"
      },
      "source": [
        "# If you want to run this outside of Colab you will need to install the\n",
        "# appropriate libraries, e.g, Pytorch, etc.\n",
        "! pip install adversarial-robustness-toolbox\n",
        "! pip install IPython\n",
        "! pip install yaspin\n",
        "\n",
        "! git clone https://github.com/jalane76/adversarial-attacks-tutorial.git repo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtTFhkbNaZiF"
      },
      "source": [
        "from art.attacks.evasion import FastGradientMethod\n",
        "from art.estimators.classification import PyTorchClassifier\n",
        "from art.utils import load_mnist\n",
        "import IPython\n",
        "from IPython.display import display\n",
        "from IPython.display import Image\n",
        "import matplotlib\n",
        "from matplotlib.colors import TwoSlopeNorm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from yaspin import yaspin\n",
        "from yaspin.spinners import Spinners"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxK21jIeDkjD"
      },
      "source": [
        "## Set up app parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mawb8Gm0bMpK"
      },
      "source": [
        "rand_seed = 978614566\n",
        "np.random.seed(rand_seed)\n",
        "torch.manual_seed(rand_seed)\n",
        "\n",
        "image_width = 28\n",
        "image_height = 28\n",
        "input_shape = (1, 28, 28)\n",
        "\n",
        "batch_size = 64\n",
        "num_epochs = 3\n",
        "num_labels = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OH095STvDuxT"
      },
      "source": [
        "# We'll use the MNIST dataset so load it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYKWIf5lbiqi"
      },
      "source": [
        "with yaspin(spinner=Spinners.aesthetic, text=\"Loading MNIST data...\"):\n",
        "  (\n",
        "    (x_train, y_train),\n",
        "    (x_test, y_test),\n",
        "    min_pixel_value,\n",
        "    max_pixel_value,\n",
        "  ) = load_mnist()\n",
        "\n",
        "  clip_values = (min_pixel_value, max_pixel_value)\n",
        "\n",
        "  # Swap axes to PyTorch's NCHW format\n",
        "  x_train = np.transpose(x_train, (0, 3, 1, 2)).astype(np.float32)\n",
        "  x_test = np.transpose(x_test, (0, 3, 1, 2)).astype(np.float32)\n",
        "\n",
        "print(f\"{x_train.shape} training data shape\")\n",
        "print(f\"{x_test.shape} test data shape\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqzcOr8mD6dH"
      },
      "source": [
        "# Let's see the first few benign samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbd2S9gDh9cg",
        "collapsed": true
      },
      "source": [
        "with yaspin(spinner=Spinners.aesthetic, text=\"Plotting benign samples...\"):\n",
        "  num_samples = 5\n",
        "  num_rows = 1\n",
        "\n",
        "  fig, axes = plt.subplots(num_rows, num_samples, sharex=True, sharey=True, squeeze=False)\n",
        "  fig.set_figheight(4.0 * num_rows)\n",
        "  fig.set_figwidth(4.0 * num_samples)\n",
        "  for sample_idx in range(num_samples):\n",
        "    sample_axis = axes[0, sample_idx]\n",
        "    sample = x_train[sample_idx, 0, :, :]\n",
        "    sample_axis.imshow(\n",
        "      sample, aspect=\"equal\", interpolation=\"nearest\"\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7eKzeq1Ec5z"
      },
      "source": [
        "# Define the neural network and create an ART classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wO79crGufkoE"
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.conv_1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=5, stride=1)\n",
        "    self.conv_2 = nn.Conv2d(in_channels=4, out_channels=10, kernel_size=5, stride=1)\n",
        "    self.fc_1 = nn.Linear(in_features=4 * 4 * 10, out_features=100)\n",
        "    self.fc_2 = nn.Linear(in_features=100, out_features=10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv_1(x))\n",
        "    x = F.max_pool2d(x, 2, 2)\n",
        "    x = F.relu(self.conv_2(x))\n",
        "    x = F.max_pool2d(x, 2, 2)\n",
        "    x = x.view(-1, 4 * 4 * 10)\n",
        "    x = F.relu(self.fc_1(x))\n",
        "    x = self.fc_2(x)\n",
        "    return x\n",
        "\n",
        "model = Net()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "classifier = PyTorchClassifier(\n",
        "  model=model,\n",
        "  clip_values=clip_values,\n",
        "  loss=criterion,\n",
        "  optimizer=optimizer,\n",
        "  input_shape=(input_shape),\n",
        "  nb_classes=num_labels,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nN96nKYgEkTs"
      },
      "source": [
        "# Train the classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0yZo7Tk_mVe"
      },
      "source": [
        "with yaspin(spinner=Spinners.aesthetic, text=\"Training...\"):\n",
        "  classifier.fit(x_train, y_train, batch_size=batch_size, nb_epochs=num_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyW4oRo-EruU"
      },
      "source": [
        "# Test the accuracy on benign samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ko38ysEUD2rr"
      },
      "source": [
        "predictions = classifier.predict(x_test)\n",
        "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
        "print(f\"Benign accuracy: {accuracy * 100}%\")\n",
        "\n",
        "display(Image(open('repo/airplane-thumbs-up.gif','rb').read()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzqeKz3qE4XY"
      },
      "source": [
        "#    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjoovhB9FI-W"
      },
      "source": [
        "# Now generate FGSM attacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvEKpttzHhd6"
      },
      "source": [
        "with yaspin(spinner=Spinners.aesthetic, text=\"Generating attacks...\"):\n",
        "  attack = FastGradientMethod(estimator=classifier, eps=0.2)\n",
        "  x_test_adv = attack.generate(x=x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooC24lr5FZMd"
      },
      "source": [
        "# Now let's compare the first few benign samples with their evil twins"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibQv0_T1KdUT"
      },
      "source": [
        "with yaspin(spinner=Spinners.aesthetic, text=\"Generating training attacks and retraining...\"):\n",
        "  num_samples = 5\n",
        "  num_rows = 2\n",
        "\n",
        "  fig, axes = plt.subplots(num_rows, num_samples, sharex=True, sharey=True, squeeze=False)\n",
        "  fig.set_figheight(4.0 * num_rows)\n",
        "  fig.set_figwidth(4.0 * num_samples)\n",
        "  for sample_idx in range(num_samples):\n",
        "    sample_axis = axes[0, sample_idx]\n",
        "    sample = x_test[sample_idx, 0, :, :]\n",
        "    sample_axis.imshow(\n",
        "      sample, aspect=\"equal\", interpolation=\"nearest\"\n",
        "    )\n",
        "\n",
        "    evil_twin_axis = axes[1, sample_idx]\n",
        "    evil_twin = x_test_adv[sample_idx, 0, :, :]\n",
        "    evil_twin_axis.imshow(\n",
        "        evil_twin, aspect=\"equal\", interpolation=\"nearest\"\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4bsLJ7uFhzq"
      },
      "source": [
        "# Test the accuracy on the adversarial examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFtuuG-QHt2t"
      },
      "source": [
        "predictions = classifier.predict(x_test_adv)\n",
        "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
        "print(f\"Adversarial accuracy: {accuracy * 100}%\")\n",
        "\n",
        "display(Image(open('repo/airplane-sweat.gif','rb').read()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pd5rJxybF3jq"
      },
      "source": [
        "# Let's augment the training data with adversarial examples and retrain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76rR93hzOh9t"
      },
      "source": [
        "with yaspin(spinner=Spinners.aesthetic, text=\"Generating training attacks and retraining...\"):\n",
        "  x_train_adv = attack.generate(x=x_train)\n",
        "  classifier.fit(x_train_adv, y_train, batch_size=batch_size, nb_epochs=num_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3KuJ4AOF_b3"
      },
      "source": [
        "# Retest the accuracy after retraining"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAPLATqAPwMa"
      },
      "source": [
        "predictions = classifier.predict(x_test_adv)\n",
        "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
        "print(f\"Retrained accuracy: {accuracy * 100}%\")\n",
        "\n",
        "display(Image(open('repo/airplane-happy.gif','rb').read()))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}